{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survey Validation Data Challenge - Summer 2019\n",
    "\n",
    "### Notebook II: BGS GAMA field run.\n",
    "\n",
    "The purpose of this notebook is to simulate DESI-like spectra of BGS targets bootstrapped from an input set of GAMA targets and redshifts, and then to run the spectra through the full DESI pipeline.\n",
    "See  https://desi.lbl.gov/trac/wiki/BrightGalaxyWG/SVPlan\n",
    "\n",
    "* Successful run on 18.12 up to spectro db production -- module swap fiberassign/1.0.0 required for assignment, which doesn't work beyond 18.12 (i.e. 19.2 and master).  Fiberassign dislikes sv_desi_target aswell.\n",
    "\n",
    "* --survey sv1 is good for select_mock_targets.\n",
    "\n",
    "* Stuck at 'rawdata' ready state in spectro database - preventing preproc and other dependencies running.\n",
    "\n",
    "* Initial config. of desisurvey to point to sv tiles file; necessary for add_calibration exposures. \n",
    "\n",
    "* Got surveysim up and running by creating single pass, \"LO\" only groups in rules-sv.yaml\n",
    "\n",
    "* Correct format for mock-targets.yaml?  E.g. list of contaminants / targets.  See also https://github.com/desihub/fiberassign/issues/198\n",
    "\n",
    "* As per https://github.com/desihub/survey-validation/blob/master/sv-bgs-decals/main.py, set NUMOBS_MORE=4 in .mtl prior to assignment and specified calls to --nstarpetal 20  --nskypetal 80.\n",
    "\n",
    "* See for truth.fits warnings:  /global/cscratch1/sd/mjwilson/svdc-summer2018/targets/join_mock_targets.out\n",
    "\n",
    "*  BGS target selection?  SV bits?  \n",
    "\n",
    "*  ERROR:run_target_qa:37:<module>: The weightmap file was not passed so systematics cannot be tracked. \n",
    "   Try again sending --nosystematics.\n",
    "    \n",
    "*  Add Bright star mask and brick boundaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import desitarget\n",
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import time\n",
    "import pylab as pl\n",
    "import subprocess\n",
    "import glob\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitsio\n",
    "import astropy.io.fits   as fits\n",
    "\n",
    "from   astropy.table     import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='ticks', font_scale=1.6, palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting at {}\".format(time.asctime()))\n",
    "\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Some of these are imported just to establish versions\n",
    "#- but aren't used in the notebook itself\n",
    "import desisim\n",
    "import desispec.io\n",
    "from   desispec.scripts import pipe\n",
    "import desitarget.io\n",
    "import desimodel.io\n",
    "import desimodel.footprint\n",
    "import desisurvey\n",
    "import surveysim\n",
    "import specsim\n",
    "from   surveysim.util import add_calibration_exposures\n",
    "import desiutil.depend\n",
    "import specter\n",
    "import redrock\n",
    "import simqso\n",
    "\n",
    "from   desiutil import depend\n",
    "\n",
    "\n",
    "##  Define versions: in flux. \n",
    "print(os.environ['DESIMODULES'])\n",
    "\n",
    "deps = dict()\n",
    "\n",
    "depend.add_dependencies(deps)\n",
    "depend.setdep(deps, 'simqso', simqso.__version__)\n",
    "\n",
    "for p in ('dust', 'desimodules'):\n",
    "    if p.upper() + '_VERSION' in os.environ:\n",
    "        depend.setdep(deps, p, os.environ[p.upper() + '_VERSION'])\n",
    "\n",
    "for codename, version in depend.iterdep(deps):\n",
    "    print('  {:12s} {}'.format(codename, version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define various directories and other io.\n",
    "\n",
    "Define and create directories under `$DESI_ROOT/datachallenge/svdc-summer2018` and set environment variables for this mapping:\n",
    "\n",
    "| Directory             | NB variable   | Environment Variable                              |\n",
    "|-----------------------|---------------|---------------------------------------------------|\n",
    "| survey/               | surveydir     | \\$DESISURVEY_OUTPUT                               |\n",
    "| targets/              | targetdir     |                                                   |\n",
    "| fiberassign/          | fibassigndir  |                                                   |\n",
    "| spectro/redux/mini/   | reduxdir      | \\$DESI_SPECTRO_REDUX/\\$SPECPROD                   |\n",
    "| spectro/sim/mini/     | simdatadir    | \\$DESI_SPECTRO_DATA = \\$DESI_SPECTRO_SIM/$PIXPROD |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    codedir = os.path.join(os.getenv('HOME'), 'desi', 'survey-validation', 'svdc-summer2018')\n",
    "\n",
    "    #  Large file output. \n",
    "    basedir = os.path.join(os.getenv('SCRATCH'), 'svdc-summer2018', 'master')\n",
    "    \n",
    "else:\n",
    "    codedir = os.path.join(os.getenv('DESI_PRODUCT_ROOT'), 'survey-validation', 'svdc-summer2018')\n",
    "    basedir = os.path.join(os.getenv('DESI_ROOT'), 'datachallenge', 'svdc-summer2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(codedir)\n",
    "print(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_sv                            = 'sv-'  ## ['sv-']\n",
    "\n",
    "surveydir                        = os.path.join(os.getenv('DESI_ROOT'), 'datachallenge', 'surveysim2017', 'depth_0m')  \n",
    "targetdir                        = os.path.join(basedir, is_sv + 'targets')\n",
    "\n",
    "fibassigndir                     = os.path.join(basedir, is_sv + 'fiberassign')\n",
    "\n",
    "os.environ['DESISURVEY_OUTPUT']  = surveydir\n",
    "\n",
    "os.environ['DESI_SPECTRO_REDUX'] = os.path.join(basedir, is_sv + 'spectro', 'redux')\n",
    "os.environ['DESI_SPECTRO_SIM']   = os.path.join(basedir, is_sv + 'spectro', 'sim')\n",
    "\n",
    "os.environ['PIXPROD']            = 'bgs-gama'\n",
    "os.environ['SPECPROD']           = 'bgs-gama'\n",
    "\n",
    "reduxdir                         = os.path.join(os.environ['DESI_SPECTRO_REDUX'], os.environ['SPECPROD'])\n",
    "simdatadir                       = os.path.join(os.environ['DESI_SPECTRO_SIM'],   os.environ['PIXPROD'])\n",
    "\n",
    "os.environ['DESI_SPECTRO_DATA']  = simdatadir\n",
    "\n",
    "for dd in (surveydir, targetdir, fibassigndir, reduxdir, simdatadir):\n",
    "    os.makedirs(dd, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplefile                       = os.path.join(basedir, 'bgs-gama-sample.fits')\n",
    "surveyconfigfile                 = os.path.join(codedir, 'survey-config.yaml')\n",
    "surveyrulesfile                  = os.path.join(codedir, 'rules.yaml')\n",
    "\n",
    "##  Generated by cell 43; overwrite of Dawson tiles to Dark and Bright (program / conditions).\n",
    "tilesfile                        = os.path.join(basedir, 'tiles', 'bgs-gama-tiles-bright.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the random seed for reproducibility of the survey simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Required for surveysim calls (propagates to desisurvey.tiles, see this for further info.).\n",
    "config                 = desisurvey.config.Configuration()                                                                                                                                       \n",
    "config.tiles_file.set_value(tilesfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed                   =   123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside_mock_targets     =   64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify which steps should be redone (only used if the output files already exist).\n",
    "\n",
    "If any of the following arguments are *True* then all the associated output files and plots will be recreated.  Warning: many of these steps are time-consuming (especially the mock spectra portion of the pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_tiles        =   True\n",
    "overwrite_surveysim    =   True\n",
    "overwrite_mock_spectra =   True\n",
    "overwrite_join_spectra =   True\n",
    "overwrite_fiberassign  =   True\n",
    "overwrite_simspec      =   True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the parent sample of GAMA targets.\n",
    "This parent sample was written by the *bgs-gama-sample.ipynb* notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gama_sample():\n",
    "    if os.path.isfile(samplefile):\n",
    "        gama = Table(fitsio.read(samplefile, ext=1))\n",
    "        print('Read {} objects from {}'.format(len(gama), samplefile))\n",
    "        \n",
    "    else:\n",
    "        print('Sample file {} not found!'.format(samplefile))\n",
    "        gama = []\n",
    "        \n",
    "    return gama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gama = read_gama_sample()\n",
    "gama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the tiling of the G02, G09, G12, and G15 GAMA fields. (Remaining G23 field is shallower, 19.2).\n",
    "\n",
    "Here, we use a tiling solution generated by Kyle Dawson but we change the program name to DARK and set OBSCONDITIONS to zero (=DARK) until the appropriate hooks can be added to *desisurvey*.\n",
    "G02 was somewhat redefined during the course of the survey. As a result only the part north of âˆ’6 deg was observed to high completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dawson2dark_tiles():\n",
    "    \"\"\"\n",
    "    Ad hoc changes to the nominal tile file so we can get desisurvey running.\n",
    "    \"\"\"\n",
    "    dawsonfile = os.path.join(basedir, 'tiles', 'bgs-gama-tiles-kdawson.fits')\n",
    "\n",
    "    if os.path.isfile(dawsonfile):\n",
    "        '''\n",
    "        PROGRAM:  'BGS_SV', \n",
    "        \n",
    "        'OBSCONDITIONS':  \n",
    "        4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4,\n",
    "        1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4,\n",
    "        4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1,\n",
    "        4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4, 1, 4, 4,\n",
    "        1, 4]\n",
    "        \n",
    "        tiles.pass_program\n",
    "\n",
    "        {0: 'DARK',\n",
    "         1: 'DARK',\n",
    "         2: 'DARK',\n",
    "         3: 'DARK',\n",
    "         4: 'GRAY',\n",
    "         5: 'BRIGHT',\n",
    "         6: 'BRIGHT',\n",
    "         7: 'BRIGHT'} \n",
    "        '''\n",
    "\n",
    "        tiles = Table(fitsio.read(dawsonfile, ext=1))\n",
    "        \n",
    "        print('Updating PROGRAM and OBSCONDITIONS in {}'.format(dawsonfile))\n",
    "        \n",
    "        ##  Normal Bright program. \n",
    "        tiles['PASS']          =       5\n",
    "        tiles['PROGRAM']       = 'BRIGHT'\n",
    "        tiles['OBSCONDITIONS'] =       4\n",
    "        \n",
    "        brightfile = basedir + '/tiles/bgs-gama-tiles-bright.fits'\n",
    "        \n",
    "        print('Writing {}'.format(brightfile))\n",
    "        \n",
    "        tiles.write(brightfile, overwrite=True)\n",
    "\n",
    "\n",
    "        ##  Normal Dark program.\n",
    "        tiles['PASS']          = 1\n",
    "        tiles['PROGRAM']       = 'DARK'\n",
    "        tiles['OBSCONDITIONS'] = 0\n",
    "        \n",
    "        darkfile = basedir + '/tiles/bgs-gama-tiles-dark.fits'\n",
    "        \n",
    "        print('Writing {}'.format(darkfile))\n",
    "        \n",
    "        tiles.write(darkfile, overwrite=True)\n",
    "    \n",
    "    else:\n",
    "        print('Dawson tiles file {} not found!'.format(dawsonfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tile(ra, dec, r=1.606, color='k', ax=None):\n",
    "    '''\n",
    "    Approximate plot of tile location\n",
    "    '''\n",
    "    ang = np.linspace(0, 2*np.pi, 100)\n",
    "    x   = ra  + r*np.cos(ang)/np.cos(np.radians(dec))\n",
    "    y   = dec + r*np.sin(ang)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot(x,y, '-', color=color, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gama_tiles(overwrite=False):\n",
    "    \"\"\"\n",
    "    Read the tiles file.\n",
    "    \"\"\"\n",
    "    \n",
    "    if overwrite:\n",
    "        dawson2dark_tiles()\n",
    "    \n",
    "    if os.path.isfile(tilesfile):\n",
    "        tiles = Table(fitsio.read(tilesfile, ext=1))\n",
    "        \n",
    "        print('Read {} tiles from {}'.format(len(tiles), tilesfile))\n",
    "        \n",
    "    else:\n",
    "        print('Tiles file {} not found!'.format(tilesfile))\n",
    "        \n",
    "        tiles = []\n",
    "    \n",
    "    return tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_gama_tiles(gama=None, tiles=None, gamafield=None, overwrite=False):\n",
    "    if gama is None:\n",
    "        gama  = read_gama_sample()\n",
    "\n",
    "    if tiles is None:\n",
    "        tiles = read_gama_tiles()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10, 6))\n",
    "    ax      =  ax.reshape(4)\n",
    "    \n",
    "    for thisax, field in zip(ax, sorted(set(gama['FIELD']))):\n",
    "        infield = gama['FIELD'] == field\n",
    "    \n",
    "        if np.count_nonzero(infield) > 0:\n",
    "            thisax.scatter(gama['RA'][infield], gama['DEC'][infield], \n",
    "                           s=1, alpha=0.5, marker='s')\n",
    "        \n",
    "            ww = ( (tiles['RA'] > gama['RA'][infield].min()) * (tiles['RA'] < gama['RA'][infield].max()) * \n",
    "                   (tiles['DEC'] > gama['DEC'][infield].min()) * (tiles['DEC'] < gama['DEC'][infield].max()) )\n",
    "            \n",
    "            ## tiles[ww].write(basedir + '/tiles/bgs-gama-tiles-%s.fits' % field, overwrite=True)\n",
    "            \n",
    "            for tt in tiles[ww]:\n",
    "                plot_tile(tt['RA'], tt['DEC'], ax=thisax)\n",
    "            \n",
    "        thisax.set_xlabel('RA')\n",
    "        thisax.set_ylabel('Dec')\n",
    "        \n",
    "        thisax.invert_xaxis()\n",
    "        \n",
    "        thisax.set_title(field)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if overwrite:\n",
    "        pngfile = os.path.join(basedir, 'qaplots', 'qa-gama-tiles.png')\n",
    "        print('Writing {}'.format(pngfile))\n",
    "        fig.savefig(pngfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = read_gama_tiles(overwrite=overwrite_tiles)\n",
    "tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_gama_tiles(gama, tiles, overwrite=overwrite_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Write bgs-gama tile IDs to .txt for fiberassign --surveytiles. \n",
    "fname = tilesfile.split('.')[0] + '.txt'\n",
    "\n",
    "print('Writing %s.' % fname)\n",
    "\n",
    "np.savetxt(tilesfile.split('.')[0] + '.txt', tiles['TILEID'], fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the redshift distribution of the G02, G09, G12, and G15 GAMA fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Plot GAMA redshift distribution. \n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "dz      = 0.05 \n",
    "zbins   = np.arange(0.0, 0.7, dz)\n",
    "\n",
    "for field in sorted(set(gama['FIELD'])):\n",
    "    infield   = gama['FIELD'] == field\n",
    "    counts, _ = np.histogram(gama['Z'][infield], bins=zbins)\n",
    "    \n",
    "    pl.plot(zbins[:-1], counts, label=field)\n",
    "    \n",
    "ax.set_xlim(0.0, 0.75)\n",
    "\n",
    "ax.set_xlabel('redshift')\n",
    "ax.set_ylabel(r'Counts per $\\Delta z = %.3lf$' % dz)\n",
    "\n",
    "ax.legend(ncol=2)    \n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run survey simulations (successful!  requires rules-sv.yaml)\n",
    "\n",
    "The code below enables one to simulate SV observations of the GAMA fields using *desisurvey*:  This provides exposure times etc. \n",
    "However, since the dates of SV are still uncertain (and three of the four GAMA fields are spring or late-fall fields), we have opted to simulate observing conditions by simply drawing from the full-survey simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "##  Change output_path in config file to e.g. /global/cscratch1/sd/mjwilson/svdc-summer2018/survey\n",
    "configfile      = os.path.join(basedir + '/survey/desisurvey-config.yaml')\n",
    "\n",
    "if os.path.exists(basedir + '/survey/surveyinit.fits'):\n",
    "    print('surveyinit.fits already exists; skipping surveyinit')\n",
    "\n",
    "else:\n",
    "    logfilename = os.path.join(basedir + '/survey/surveyinit.log')\n",
    "    cmd         = 'surveyinit --config-file {}'.format(configfile)\n",
    "\n",
    "    print('Running {}'.format(cmd))\n",
    "    \n",
    "    print('Starting at {}; should take ~2 minutes'.format(time.asctime()))\n",
    "    \n",
    "    with open(logfilename, 'a') as logfile:\n",
    "        err = subprocess.call(cmd.split(), stderr=logfile, stdout=logfile)\n",
    "    \n",
    "        if err != 0:\n",
    "            print('surveyinit failed err={}; see {}'.format(err, logfilename))\n",
    "            raise RuntimeError\n",
    "        \n",
    "        else:\n",
    "            print('Done at {}'.format(time.asctime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Error:  No tiles with priority > 0 available.\n",
    "rulesfile         = os.path.join(basedir + '/survey/rules-sv.yaml')\n",
    "surveysim_expfile = os.path.join(basedir + '/survey/exposures_surveysim.fits')\n",
    "\n",
    "if os.path.exists(surveysim_expfile):\n",
    "    print('Survey sims already done; skipping')\n",
    "\n",
    "else:\n",
    "    logfilename = os.path.join(basedir + '/survey/surveysim.log')\n",
    "\n",
    "    cmd = 'surveysim --config-file {} --rules {} --save-restore'.format(configfile, rulesfile)\n",
    "    \n",
    "    print('Running {}'.format(cmd))\n",
    "    \n",
    "    print('Starting at {}; should take a few seconds'.format(time.asctime()))\n",
    "    \n",
    "    with open(logfilename, 'a') as logfile:\n",
    "        err = subprocess.call(cmd.split(), stderr=logfile, stdout=logfile)\n",
    "        \n",
    "        if err != 0:\n",
    "            print('surveysim failed err={}; see {}'.format(err, logfilename))\n",
    "            \n",
    "            raise RuntimeError\n",
    "        \n",
    "        else:\n",
    "            print('done at {}'.format(time.asctime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab SV-like exposures (matching EBV and program) from 2017 survey simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_survey_simulations(tiles, overwrite=False, seed=None):\n",
    "    '''\n",
    "    Generate the exposures file by drawing from the 2017 full-survey simulations.\n",
    "    '''\n",
    "    import copy\n",
    "    import desisurvey\n",
    "    \n",
    "    from   astropy.table import Column\n",
    "    \n",
    "    \n",
    "    expfile = os.path.join(surveydir, 'exposures.fits')\n",
    "    \n",
    "    if overwrite or not os.path.isfile(expfile):        \n",
    "        from astropy.table  import vstack\n",
    "        from surveysim.util import add_calibration_exposures\n",
    "\n",
    "        \n",
    "        config       = desisurvey.config.Configuration()                                                                                                                                       \n",
    "        config.tiles_file.set_value(tilesfile)\n",
    "        \n",
    "        rand         = np.random.RandomState(seed)\n",
    "        \n",
    "        simexpfile   = os.path.join(os.getenv('DESI_ROOT'), 'datachallenge', 'surveysim2017',   'depth_0m', 'exposures.fits')\n",
    "        #simexpfile  = os.path.join(os.getenv('DESI_ROOT'), 'datachallenge', 'svdc-summer2018', 'survey',   'exposures.fits')\n",
    "        #simexpfile  = os.path.join(os.getenv('DESI_ROOT'), 'datachallenge', 'surveysim2018',   'survey',   'exposures.fits')\n",
    "        \n",
    "        if not os.path.isfile(simexpfile):\n",
    "            print('Exposures file {} not found!'.format(simexpfile))\n",
    "            raise IOError\n",
    "\n",
    "        exp = Table.read(simexpfile)\n",
    "\n",
    "        print('Read {} parent exposures from {}'.format(len(exp), simexpfile))\n",
    "\n",
    "        # flag CR splits.  CR split? \n",
    "        _, uniq = np.unique(exp['TILEID'].data, return_index=True)\n",
    "        \n",
    "        explist = []\n",
    "        \n",
    "        ##  Range of EBV for tiles:  0.0504712 0.0192004    \n",
    "        for tt in tiles:\n",
    "            # Find exposures with the correct PROGRAM and close in Galactic \n",
    "            # reddening and then choose one at random (with uniform probability).\n",
    "            # If there is more than one exposure, take both (CR split).            \n",
    "            ww = np.where( (exp['PROGRAM'][uniq] == tt['PROGRAM']) * \n",
    "                           (np.abs(exp['EBMV'][uniq]-tt['EBV_MED']) < 0.02) )[0]\n",
    "            \n",
    "            if np.count_nonzero(ww) == 0:\n",
    "                ww = np.where( (exp['PROGRAM'][uniq] == tt['PROGRAM']) * \n",
    "                               (np.abs(exp['EBMV'][uniq]-tt['EBV_MED']) < 0.051) )[0]\n",
    "                \n",
    "                if np.count_nonzero(ww) == 0:\n",
    "                    print('Insufficient comparable exposures!')\n",
    "                    raise ValueError\n",
    "                \n",
    "            # choose one at random.\n",
    "            this = rand.choice(ww)\n",
    "            \n",
    "            # bring back CR splits.\n",
    "            these = exp['TILEID'] == exp['TILEID'][uniq][this]\n",
    "            \n",
    "            _explist = vstack(exp[these])\n",
    "            \n",
    "            # Replace exposure data with criteria for Kyle's tiles.\n",
    "            _explist['TILEID'] = tt['TILEID']\n",
    "            _explist['PASS']   = tt['PASS']\n",
    "            _explist['EBMV']   = tt['EBV_MED']\n",
    "            _explist['RA']     = tt['RA']\n",
    "            _explist['DEC']    = tt['DEC']\n",
    "            \n",
    "            explist.append(_explist)\n",
    "\n",
    "        explist                = vstack(explist)\n",
    "        \n",
    "        # Assign all 94 tiles to a single (wonderful) NIGHT and MJD.\n",
    "        this                   = np.where(exp['NIGHT'].data == '20191201')[0][0]\n",
    "        explist['NIGHT'][:]    = exp['NIGHT'][this]\n",
    "        explist['MJD'][:]      = exp['MJD'][this]\n",
    "        \n",
    "        # Add monotonically increasing epsilon perturbation to MJD to beat diff(MJD) > 0 catch in surveysim/util.py  \n",
    "        epsilons               = 1.e-1 * np.sort(np.random.uniform(0., 1., len(explist['MJD'])))\n",
    "        explist['MJD']        += epsilons\n",
    "        \n",
    "        '''\n",
    "        Deprecated:  instead set desisurvey config.  See desisurvey.tiles\n",
    "        \n",
    "        # Save tile ID hack for add_calibration_exposures. \n",
    "        _keepTileIDs           = copy.copy(explist['TILEID'].quantity)\n",
    "\n",
    "        # Rewrite tile IDs to nominal desi for add_calibration_exposures error. \n",
    "        desi_tileIDs           = desisurvey.tiles.get_tiles()\n",
    "        \n",
    "        explist['TILEID']      = desi_tileIDs.tileID[:len(explist['TILEID'])]\n",
    "        '''     \n",
    "        explist                = add_calibration_exposures(explist, flats_per_night=1, arcs_per_night=1)\n",
    "\n",
    "        # Rewrite nominal desi tile program to bright. \n",
    "        explist['PROGRAM'][2:] = 'BRIGHT'\n",
    "        \n",
    "        # Reset TileIDs.\n",
    "        '''\n",
    "        Deprecated:  instead set desisurvey config.  See desisurvey.tiles\n",
    "        explist['TILEID']  = Column(data=np.concatenate((np.array([-1, -1]), _keepTileIDs)), name='TILEID')\n",
    "        '''\n",
    "\n",
    "        # sequential IDs\n",
    "        explist['EXPID']       = np.arange(len(explist))\n",
    "        \n",
    "    else:\n",
    "        print('Simulated observing already completed.')\n",
    "        explist = Table.read(expfile)\n",
    "        print('Read {} exposures from {}'.format(len(explist), expfile))\n",
    "\n",
    "    return explist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time explist = survey_simulations(tiles, overwrite=overwrite_surveysim)\n",
    "%time explist  = sample_survey_simulations(tiles, overwrite=overwrite_surveysim, seed=seed)\n",
    "explist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Alter BGS MOON PARAMETER dependence - hack around survey sim;  Stripped from minitest, but useful?\n",
    "\n",
    "The default MOONALT, MOONSEP, and MOONFRAC columns are data model placeholders but not filled in with meaningful values. Correct that. \n",
    "\n",
    "Notes:\n",
    "the code below is approximate (but still better than using MOONALT=-10 for BRIGHT exposures) surveysim doesn't currently vary the bright exposure time for lunar parameters (!), so filling this in with actual parameters instead of median defaults is arguably the wrong thing to do, but it does give us a variation of conditions from which one could calculate how the exposure times should vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import desisurvey.ephem\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', message=r'Tried to get polar motions for times after IERS data.')\n",
    "\n",
    "def add_moon_params(explist):\n",
    "    '''\n",
    "    Fills MOONFRAC, MOONALT, MOONSEP columns in explist.\n",
    "    '''    \n",
    "\n",
    "    ephem_file = glob.glob(basedir + '/survey/ephem*.fits')[0]\n",
    "    ephem      = Table.read(ephem_file)\n",
    "    \n",
    "    explist['MOONFRAC'] = np.interp(explist['MJD'], ephem['brightdusk'], ephem['moon_illum_frac'])\n",
    "\n",
    "    ii = np.searchsorted(ephem['brightdusk'], explist['MJD'])-1\n",
    "\n",
    "    assert np.all(ii>=0)\n",
    "    \n",
    "    for i, j in zip(ii, range(len(explist['MJD']))):\n",
    "        if explist['FLAVOR'][j] != 'science':\n",
    "            continue\n",
    "        moon                  = desisurvey.ephem.get_object_interpolator(ephem[i], 'moon', altaz=True)\n",
    "        mjd                   = explist['MJD'][j]\n",
    "        explist['MOONALT'][j] = moon(mjd)[0]\n",
    "        moon_dec, moon_ra     = desisurvey.ephem.get_object_interpolator(ephem[i], 'moon', altaz=False)(mjd)        \n",
    "        phi1, phi2            = np.radians(moon_dec), np.radians(explist['DEC'][j])\n",
    "        theta1, theta2        = np.radians(moon_ra), np.radians(explist['RA'][j])\n",
    "        \n",
    "        #- Haversine formula\n",
    "        d                     = 2*np.arcsin(np.sqrt(np.sin(0.5*(phi2-phi1))**2 + np.cos(phi1)*np.cos(phi2)*np.sin(0.5*(theta2-theta1))**2))\n",
    "        \n",
    "        explist['MOONSEP'][j] = np.degrees(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  add_moon_params(explist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write exposure list. \n",
    "explist.write(basedir + '/survey/bgs-gama-exposures.fits', format='fits', overwrite='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize which healpixels cover the observed tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_healpix(nside, pixels, ax=None):\n",
    "    '''\n",
    "    Plot healpix boundaries; doesn't work at RA wraparound.\n",
    "    '''\n",
    "    if ax is None:\n",
    "        fig, ax    = plt.subplots()\n",
    "        \n",
    "    for p in pixels:\n",
    "        xyz        = hp.boundaries(nside, p, nest=True)\n",
    "        theta, phi = hp.vec2ang(xyz.T)\n",
    "        theta      = np.concatenate([theta, theta[0:1]])\n",
    "        phi        = np.concatenate([phi, phi[0:1]])\n",
    "        ra, dec    = np.degrees(phi), 90-np.degrees(theta)\n",
    "        \n",
    "        ax.plot(ra, dec, '.', color='0.6') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiles2pixels(tiles, nside=64, fact=2**8):\n",
    "    import desimodel.footprint\n",
    "    \n",
    "    \n",
    "    pixels = desimodel.footprint.tiles2pix(nside, tiles, fact=fact)\n",
    "    nexp   = np.count_nonzero(np.in1d(explist['TILEID'], tiles['TILEID']))\n",
    "\n",
    "    print('{} tiles covered by {} exposures and {} nside={} healpixels'.format(len(tiles), nexp, len(pixels), nside))\n",
    "\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_observed_tiles():\n",
    "    isbright = explist['PROGRAM'] == 'BRIGHT'\n",
    "    isgray   = explist['PROGRAM'] == 'GRAY'\n",
    "    isdark   = explist['PROGRAM'] == 'DARK'\n",
    "    \n",
    "    fig, ax  = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.plot(explist['RA'][isdark], explist['DEC'][isdark], 'o', color='deepskyblue', ms=10, mew=2, label='Dark exposure', alpha=1.0)\n",
    "    ax.plot(  tiles['RA'],           tiles['DEC'],         'o', ms=5, color='k', label='Requested tiles', alpha=0.5)\n",
    "    \n",
    "    if np.sum(isgray) > 0:\n",
    "        ax.plot(explist['RA'][isgray], explist['DEC'][isgray], 's', \n",
    "                color='0.6', ms=10, label='gray')\n",
    "    \n",
    "    if np.sum(isbright) > 0:\n",
    "        ax.plot(explist['RA'][isbright], explist['DEC'][isbright], 'd', \n",
    "                color='m', ms=5, mew=2, label='bright')\n",
    "    \n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    ax.set_xlabel('RA')\n",
    "    ax.set_ylabel('Dec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_observed_tiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_tiles2pixels(tiles, nside=64, overwrite=False, plotit=False):\n",
    "  pixels = tiles2pixels(tiles, nside=nside)\n",
    "  \n",
    "  if plotit:\n",
    "    ##  Get science rather than calibration exposures.\n",
    "    sci    = explist['FLAVOR'] == 'science'\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "\n",
    "    ax1.scatter(tiles['RA'], tiles['DEC'], marker='s', edgecolor='k', facecolor='none', lw=2, label='Tile Centers')\n",
    "    ax1.scatter(explist['RA'][sci], explist['DEC'][sci], marker='o', alpha=0.7, label='Science exposures', s=6)\n",
    "    \n",
    "    ax1.legend(loc='upper left', markerscale=1.5)\n",
    "\n",
    "    ax1.invert_xaxis()\n",
    "    ax1.set_ylim(-7.5, 7.5)\n",
    "    \n",
    "    ax1.set_xlabel('RA')\n",
    "    ax1.set_ylabel('Dec')\n",
    "\n",
    "    plot_healpix(nside, pixels, ax=ax2)\n",
    "    \n",
    "    color = dict(DARK='m', GRAY='b', BRIGHT='m')\n",
    "    \n",
    "    for program in ['DARK', 'GRAY', 'BRIGHT']:\n",
    "        ii = (tiles['PROGRAM'] == program)\n",
    "        ax2.plot(tiles['RA'][ii], tiles['DEC'][ii], '.', color=color[program], alpha=1.)\n",
    "        jj = tiles['PROGRAM'] == program\n",
    "\n",
    "        for t in tiles[jj]:\n",
    "            plot_tile(t['RA'], t['DEC'], color=color[program], ax=ax2)\n",
    "            \n",
    "    xlim = ax2.get_xlim()\n",
    "    \n",
    "    ax1.set_xlim(xlim)\n",
    "    ax2.set_xlim(xlim)\n",
    "      \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if overwrite:\n",
    "        pngfile = os.path.join(basedir, 'qaplots', 'qa-gama-tiles-healpixels.png')\n",
    "        print('Writing {}'.format(pngfile))\n",
    "        fig.savefig(pngfile)        \n",
    "    \n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = qa_tiles2pixels(tiles, nside=nside_mock_targets, overwrite=overwrite_tiles)\n",
    "pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot up histograms of EXPTIME, SEEING, TRANSPARENCY, AIRMASS, MOONSEP, MOONFRAC, MOONALT.\n",
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(1, 6, figsize=(36, 6), sharey=True)\n",
    "\n",
    "ax1.hist(explist['EBMV'], bins=20, color='deepskyblue')\n",
    "ax1.set_xlabel(r'$E(B-V)$')\n",
    "\n",
    "ax2.hist(explist['SEEING'], bins=20, color='deepskyblue')\n",
    "ax2.set_xlabel(r'Seeing [arcseconds]')\n",
    "\n",
    "ax3.hist(explist['TRANSPARENCY'], bins=20, color='deepskyblue')\n",
    "ax3.set_xlabel(r'Transparency')\n",
    "\n",
    "ax4.hist(explist['AIRMASS'], bins=20, color='deepskyblue')\n",
    "ax4.set_xlabel(r'Airmass')\n",
    "\n",
    "ax5.hist(explist['MOONSEP'], bins=20, color='deepskyblue')\n",
    "ax5.set_xlabel(r'Moon separation [deg.]')\n",
    "\n",
    "ax6.hist(explist['MOONFRAC'], bins=20, color='deepskyblue')\n",
    "ax6.set_xlabel(r'Moon fraction')\n",
    "\n",
    "ax1.set_title('SV-like exposures (from 2017 sim.)\\n', fontsize=28)\n",
    "\n",
    "## \n",
    "pexp, counts = np.unique(explist['PROGRAM'], return_counts=True)\n",
    "\n",
    "print('\\n\\nProgram split:\\n')\n",
    "print(pexp)\n",
    "print(counts)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot EXPTIME vs SEEING, TRANSPARENCY, AIRMASS, MOONSEP, MOONFRAC, MOONALT.\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(36, 6), sharey=True)\n",
    "\n",
    "ax1.plot(explist['EBMV'], explist['EXPTIME'], 'o', color='deepskyblue')\n",
    "ax1.set_xlabel(r'$E(B-V)$')\n",
    "ax1.set_ylabel(r'Exposure [s]')\n",
    "\n",
    "ax2.plot(explist['SEEING'], explist['EXPTIME'], 'o', color='deepskyblue')\n",
    "ax2.set_xlabel(r'Seeing')\n",
    "ax2.set_ylabel(r'Exposure [s]')\n",
    "\n",
    "ax3.plot(explist['AIRMASS'], explist['EXPTIME'], 'o', color='deepskyblue')\n",
    "ax3.set_xlabel(r'Airmass')\n",
    "ax3.set_ylabel(r'Exposure [s]')\n",
    "\n",
    "ax4.plot(explist['MOONSEP'], explist['EXPTIME'], 'o', color='deepskyblue')\n",
    "ax4.set_xlabel(r'Moon separation [deg]')\n",
    "ax4.set_ylabel(r'Exposure [s]')\n",
    "\n",
    "ax5.plot(explist['MOONFRAC'], explist['EXPTIME'], 'o', color='deepskyblue')\n",
    "ax5.set_xlabel(r'Moon fraction')\n",
    "ax5.set_ylabel(r'Exposure [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate noiseless spectra using select_mock_targets.\n",
    "Then, merge the target, sky, and stdstar catalogs and build the Merged Target List (MTL) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  From here, process the minimal amount, e.g. one tile. \n",
    "fonetile    = basedir + '/tiles/bgs-gama-tiles-100000.fits'\n",
    "\n",
    "onetile     = Table(fitsio.read(fonetile, ext=1))\n",
    "\n",
    "##  Pixels for that one tile.\n",
    "onetile_pix = tiles2pixels(onetile, nside=64)\n",
    "\n",
    "print(onetile_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onetile['RA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_select_mock_targets_done(targetdir, pixels, verbose=True):\n",
    "    done = True\n",
    "\n",
    "    for filetype in ['targets', 'truth', 'sky', 'standards-dark', 'standards-bright']:\n",
    "        filenames = glob.glob(os.path.join(targetdir, '*', '*', '{}*.fits'.format(filetype)))\n",
    "        \n",
    "        if verbose:\n",
    "            print('{}/{} {} files'.format(len(filenames), len(pixels), filetype))\n",
    "\n",
    "        if len(filenames) != len(pixels):\n",
    "            done = False\n",
    "            \n",
    "    return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_mock_targets(tilesfile, nside=64, overwrite=False, verbose=False, mpi=True, no_spectra=False):\n",
    "    \"\"\"\n",
    "    Run select_mock_targets.\n",
    "    \n",
    "    For debugging in an interactive node:\n",
    " \n",
    "    #  Config mixes standards across both science and standards file.  Currently an issue for fiberassign/master. \n",
    "    salloc -N 15 -q interactive -L SCRATCH -C haswell -t 00:30:00 -n 30 -c 16\n",
    "\n",
    "    #  Won't do anything if the healpix split directories already exist. \n",
    "\n",
    "    mpi_select_mock_targets \n",
    "       --output_dir /global/cscratch1/sd/mjwilson/svdc-summer2018/targets\n",
    "       --config /global/homes/m/mjwilson/desi/survey-validation/svdc-summer2018/mock-targets.yaml\n",
    "       --seed 123 \n",
    "       --nproc 16 \n",
    "       --nside 64 \n",
    "       --healpixels 25912 25913 25914 25915 25916 25917 25918 25919 25962 26000 26001 26002 26003 26004 26005 26006 26007 26012 26013 26048 26050\n",
    "       --survey sv1       ##  [main, sv1] \n",
    "       \n",
    "    Note:  See cell 36 for necessary pixel list.  E.g. pixels [21883] took 16.6 minutes.\n",
    "    \"\"\"\n",
    "    logfilename = os.path.join(targetdir, 'select_mock_targets.log')\n",
    "    \n",
    "    if overwrite or not is_select_mock_targets_done(tilesfile, nside=nside, verbose=verbose):\n",
    "        print('Starting select_mock_targets at {}'.format(time.asctime()))\n",
    "        print('Logging to {}'.format(logfilename))\n",
    "\n",
    "        configfile = os.path.join(codedir, 'mock-targets.yaml')\n",
    "\n",
    "        if mpi:\n",
    "            cmd  = \"srun -A desi -N 15 -n 30 -c 16 -C haswell -t 00:60:00 --qos interactive\"\n",
    "            cmd += \" mpi_select_mock_targets --output_dir {targetdir} --config {configfile}\"\n",
    "            cmd += \" --seed {seed} --nproc 16 --nside {nside} --tiles {tilesfile} \"\n",
    "        \n",
    "        else:\n",
    "            cmd  = \"select_mock_targets --output_dir {targetdir} --config {configfile}\"\n",
    "            cmd += \" --seed {seed} --nproc 4 --nside {nside} --tiles {tilesfile} --overwrite \"\n",
    "        \n",
    "        if no_spectra:\n",
    "            cmd += \"--no-spectra\"\n",
    "        \n",
    "        cmd = cmd.format(targetdir=targetdir, tilesfile=tilesfile, \n",
    "                         configfile=configfile, seed=seed, nside=nside)\n",
    "        \n",
    "        print(cmd)\n",
    "        \n",
    "        with open(logfilename, 'w') as logfile:\n",
    "            err = subprocess.call(cmd.split(), stderr=logfile, stdout=logfile)\n",
    "            \n",
    "            if err != 0:\n",
    "                print('select_mock_targets failed err={}; see {}'.format(err, logfilename))\n",
    "                \n",
    "            else:\n",
    "                print('done at {}'.format(time.asctime()))\n",
    " \n",
    "    else:\n",
    "        print('All done with select_mock_targets; see log file {}'.format(logfilename))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Pixels [21883] took 16.6 minutes; 21 nside=64 healpixels to be processed. \n",
    "##  \n",
    "##  NOTE:  If output directories exist of given healpixel, no reprocessing will occur.  Delete first.  \n",
    "select_mock_targets(fonetile, nside=nside_mock_targets, verbose=True, mpi=True, overwrite=overwrite_mock_spectra, no_spectra=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_select_mock_targets_done(targetdir, onetile_pix, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_targets_truth_mtl(overwrite=False):\n",
    "    mtlfile     = os.path.join(targetdir, 'mtl.fits')\n",
    "    truthfile   = os.path.join(targetdir, 'truth.fits')\n",
    "    targetsfile = os.path.join(targetdir, 'targets.fits')\n",
    "\n",
    "    if (overwrite or not os.path.isfile(mtlfile) or not os.path.isfile(targetsfile) or not os.path.isfile(truthfile)):        \n",
    "        cmd = \"join_mock_targets --mockdir {} --overwrite\".format(targetdir)\n",
    "        \n",
    "        print(cmd)\n",
    "        \n",
    "        err = subprocess.call(cmd.split())\n",
    "        \n",
    "        if err != 0:\n",
    "            print('join_mock_targets failed err={}'.format(err))\n",
    "        \n",
    "        else:\n",
    "            print('Successfully joined all targets and truth catalogs.')\n",
    "        \n",
    "    else:\n",
    "        print('Using existing truth.fits {}'.format(truthfile))        \n",
    "        print('Using existing targets.fits file {}'.format(targetsfile))        \n",
    "        print('Using existing merged target list {}'.format(mtlfile))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_targets_truth_mtl(overwrite=overwrite_join_spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do basic sanity check on the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, target_hdr = fitsio.read(os.path.join(targetdir, 'targets.fits'), header=True)\n",
    "truth               = fitsio.read(os.path.join(targetdir, 'truth.fits'))\n",
    "mtl                 = fitsio.read(os.path.join(targetdir, 'mtl.fits'))\n",
    "std, std_hdr        = fitsio.read(os.path.join(targetdir, 'standards-dark.fits'), header=True)\n",
    "sky                 = fitsio.read(os.path.join(targetdir, 'sky.fits'))\n",
    "\n",
    "pl.figure(figsize = (6,4))\n",
    "\n",
    "pl.plot(mtl['RA'], mtl['DEC'], 'b,', alpha=0.1)\n",
    "pl.plot(std['RA'], std['DEC'], 'm.', alpha=0.5)\n",
    "\n",
    "pl.xlabel('RA')\n",
    "pl.ylabel('DEC')\n",
    "\n",
    "pl.xlim(225,  210)\n",
    "pl.ylim(-2.5, 4.0)\n",
    "\n",
    "pl.title('Single G15 exposure.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run target selection QA\n",
    "Successfully outputs to /global/cscratch1/sd/mjwilson/svdc-summer2018/targets/qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetfile  = os.path.join(targetdir,   'targets.fits')\n",
    "targetQAdir = os.path.join(targetdir,   'qa')\n",
    "targetQAlog = os.path.join(targetQAdir, 'target-qa.log')\n",
    "\n",
    "os.makedirs(targetQAdir, exist_ok=True)\n",
    "\n",
    "# ERROR:run_target_qa:37:<module>: The weightmap file was not passed so systematics cannot be tracked. \n",
    "# Try again sending --nosystematics.\n",
    "cmd = 'run_target_qa {} {} --mocks --nside 32 --nosystematics'.format(targetfile, targetQAdir)\n",
    "\n",
    "print(cmd)\n",
    "\n",
    "with open(targetQAlog, 'w') as logfile:\n",
    "    err = subprocess.call(cmd.split(), stdout=logfile, stderr=logfile)\n",
    "\n",
    "if err != 0:\n",
    "    print('ERROR running {}'.format(cmd))\n",
    "\n",
    "    msg = 'see {}'.format(targetQAlog)\n",
    "    \n",
    "    raise RuntimeError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "Image(targetQAdir + '/mock-nz-BGS_ANY.png',   width=8e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewrite NUMOBS_MORE in .mtl: 4 observations per target in SV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sv_numobs(numobs=4):\n",
    "  mtl = fits.open(targetdir + '/mtl.fits')\n",
    "\n",
    "  mtl[1].data['NUMOBS_MORE'][mtl[1].data['NUMOBS_MORE'] > 0] = numobs\n",
    "\n",
    "  mtl.writeto(targetdir + '/mtl.fits', overwrite=True)\n",
    "\n",
    "  print('Successfully rewritten %s/mtl.fits to SV-like NUMOBS_MORE = 4.' % targetdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_sv_numobs(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiber assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fiberassign_done(tilesfile, verbose=False):\n",
    "    \"\"\"\n",
    "    Check whether fiberassign successfully finished.\n",
    "    \"\"\"\n",
    "    \n",
    "    tiles = Table(fitsio.read(tilesfile, ext=1))\n",
    "    done  = True\n",
    "    \n",
    "    for tileid in tiles['TILEID']:\n",
    "        tilefile = os.path.join(fibassigndir, 'fiberassign_{:05d}.fits'.format(tileid))\n",
    "        \n",
    "        if not os.path.exists(tilefile):\n",
    "            done = False\n",
    "            \n",
    "            if verbose:\n",
    "                print('Missing {}'.format(tilefile))\n",
    "\n",
    "    return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fiberassign(tilesfile, overwrite=False, verbose=False):\n",
    "    '''\n",
    "    To debug:  \n",
    "    \n",
    "    salloc -N 15 -q interactive -L SCRATCH -C haswell -t 00:30:00 -n 30 -c 16\n",
    "    \n",
    "    module swap fiberassign/1.0.0\n",
    "    \n",
    "    fiberassign  --mtl /global/cscratch1/sd/mjwilson/svdc-summer2018/targets/mtl.fits \n",
    "                 --stdstar /global/cscratch1/sd/mjwilson/svdc-summer2018/targets/standards-dark.fits \n",
    "                 --sky /global/cscratch1/sd/mjwilson/svdc-summer2018/targets/sky.fits \n",
    "                 --surveytiles $HOME/desi/survey-validation/svdc-summer2018/bgs-gama-tiles-kdawson-100000.txt \n",
    "                 --footprint /global/cscratch1/sd/mjwilson/svdc-summer2018/tiles/bgs-gama-tiles-100000.fits \n",
    "                 --fibstatusfile /global/homes/m/mjwilson/desi/survey-validation/svdc-summer2018/fiberstatus.ecsv \n",
    "                 --outdir /global/cscratch1/sd/mjwilson/svdc-summer2018/fiberassign \n",
    "                 --overwrite\n",
    "                 \n",
    "                 To be added:\n",
    "\n",
    "                 --nstarpetal 20 \n",
    "                 --nskypetal 80 \n",
    "                 --overwrite\n",
    "    '''\n",
    "    \n",
    "    logfilename = os.path.join(fibassigndir, 'fiberassign.log')\n",
    "\n",
    "    if overwrite or not is_fiberassign_done(tilesfile, verbose=verbose):\n",
    "        print('Generating lists of dark and bright tiles')\n",
    "\n",
    "        tiles = Table(fitsio.read(tilesfile, ext=1))\n",
    "\n",
    "        bx, dx = None, None\n",
    "\n",
    "        for tileid, program  in zip(tiles['TILEID'], tiles['PROGRAM']):\n",
    "            if program == 'BRIGHT':\n",
    "                if bx is None:\n",
    "                    bx = open(os.path.join(fibassigndir, 'bright-tiles.txt'), 'w')\n",
    "                bx.write(str(tileid)+'\\n')\n",
    "                \n",
    "            else:\n",
    "                if dx is None:\n",
    "                    dx = open(os.path.join(fibassigndir, 'dark-tiles.txt'), 'w')\n",
    "                dx.write(str(tileid)+'\\n')\n",
    "                \n",
    "        if bx:\n",
    "            bx.close()\n",
    "        \n",
    "        if dx:\n",
    "            dx.close()\n",
    "\n",
    "        # Remove any leftover tile files\n",
    "        for tilefile in glob.glob(fibassigndir + '/tile_*.fits'):\n",
    "            os.remove(tilefile)\n",
    "\n",
    "        cmd   = \"fiberassign \"\n",
    "        cmd  += \" --mtl {}/mtl.fits\".format(targetdir)\n",
    "        cmd  += \" --stdstar {}/{{stdfile}}\".format(targetdir)\n",
    "        cmd  += \" --sky {}/sky.fits\".format(targetdir)\n",
    "        cmd  += \" --surveytiles {}/{{surveytiles}}\".format(fibassigndir)\n",
    "        cmd  += \" --footprint {tilesfile}\"\n",
    "        #cmd += \" --positioners {}/data/focalplane/fiberpos.fits\".format(os.getenv('DESIMODEL'))\n",
    "        cmd  += \" --fibstatusfile {}/fiberstatus.ecsv\".format(codedir)\n",
    "        cmd  += \" --outdir {}\".format(fibassigndir)\n",
    "\n",
    "        # Run fiberassign\n",
    "        print('Logging to {}'.format(logfilename)); print()\n",
    "        \n",
    "        with open(logfilename, 'w') as logfile:\n",
    "            for program in ['dark', 'bright']:\n",
    "                stdfile     = 'standards-{}.fits'.format(program)\n",
    "                surveytiles =      '{}-tiles.txt'.format(program)\n",
    "        \n",
    "                if os.path.isfile(os.path.join(fibassigndir, surveytiles)):\n",
    "                    cmdx = cmd.format(stdfile=stdfile, surveytiles=surveytiles,\n",
    "                                      tilesfile=tilesfile)\n",
    "                    print(cmdx)\n",
    "                \n",
    "                    err = subprocess.call(cmdx.split(), stdout=logfile, stderr=logfile)\n",
    "\n",
    "                    if err != 0:\n",
    "                        print('fiberassign failed err={}; see {}'.format(err, logfilename))\n",
    "        \n",
    "        if is_fiberassign_done(tilesfile, verbose=True):\n",
    "            print('Success; Running QA.')\n",
    "            print()\n",
    "\n",
    "            !qa-fiberassign $fibassigndir/tile*.fits --targets $targetdir/targets.fits\n",
    "        \n",
    "        else:\n",
    "            print('ERROR: missing fiberassign output files')\n",
    "        \n",
    "    else:\n",
    "        print('Finished fiber assignment; see log file {}'.format(logfilename))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Successfully run in shell  --  module swap fiberassign/1.0.0 required ... \n",
    "%time run_fiberassign(os.path.join(codedir, 'bgs-gama-tiles-%s.fits' % 'G02'), overwrite=overwrite_fiberassign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fiber assignment QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignQAdir = os.path.join(basedir, 'fiberassign', 'qa')\n",
    "assignQAlog = os.path.join(assignQAdir, 'assign-qa.log')\n",
    "\n",
    "os.makedirs(assignQAdir, exist_ok=True)\n",
    "\n",
    "cmd     = 'qa-fiberassign --verbose %s/fiberassign/tile-100000.fits --targets %s/targets.fits' % (basedir, targetdir)\n",
    "\n",
    "print(cmd)\n",
    "\n",
    "with open(assignQAlog, 'w') as logfile:\n",
    "  err = subprocess.call(cmd.split(), stdout=logfile, stderr=logfile)\n",
    "\n",
    "if err != 0:\n",
    "  print('Fiberassign QA failed err={}; see {}'.format(err, assignQAlog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine surveysim, mocks, and fiberassign into simspec files.\n",
    "\n",
    "[This step took roughly 27 minutes on my laptop with two tiles.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_newexp_done(explist, verbose=False):    \n",
    "    numnights     = len(set(explist['NIGHT']))\n",
    "    nexp          = len(explist)  #- 3 arc/night + 3 flat/night + science\n",
    "    simspecfiles  = glob.glob(simdatadir + '/*/simspec*.fits')\n",
    "    fibermapfiles = glob.glob(simdatadir + '/*/fibermap*.fits')\n",
    "    \n",
    "    if verbose:\n",
    "        print('{}/{} simspec files'.format(len(simspecfiles), nexp))\n",
    "        print('{}/{} fibermap files'.format(len(fibermapfiles), nexp))\n",
    "\n",
    "    if len(simspecfiles) != nexp:\n",
    "        return False\n",
    "    \n",
    "    elif len(fibermapfiles) != nexp:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_newexp(tilefile, explist, overwrite=False, mpi=False, dryrun=False):\n",
    "    '''\n",
    "    Run newexp.\n",
    "\n",
    "    Debug:\n",
    "        \n",
    "    salloc -N 15 -q interactive -L SCRATCH -C haswell -t 00:30:00 -n 15 -c 32\n",
    "\n",
    "    srun -A desi -N 15 -n 15 -c 32 -C haswell -t 00:120:00 --qos debug \n",
    "    \n",
    "    wrap-newexp \n",
    "         --fiberassign /global/cscratch1/sd/mjwilson/svdc-summer2018/fiberassign \n",
    "         --mockdir /global/cscratch1/sd/mjwilson/svdc-summer2018/targets \n",
    "         --obslist /global/cscratch1/sd/mjwilson/svdc-summer2018/survey/bgs-gama-exposures.fits \n",
    "         --tilefile /global/cscratch1/sd/mjwilson/svdc-summer2018/tiles/bgs-gama-tiles-100000.fits  \n",
    "         --outdir $SCRATCH/svdc-summer2018/spectro/sim/bgs-gama/ \n",
    "         --force\n",
    "         --mpi\n",
    "    \n",
    "    Note this logs directly to projectdirs/user/\n",
    "    e.g.  /global/project/projectdirs/desi/spectro/sim/mjwilson/20210421/00011517/simspec-00011517.log    \n",
    "\n",
    "    Output:\n",
    "    /global/project/projectdirs/desi/spectro/sim/mjwilson/20191201/00000000/simspec-00000000.log\n",
    "\n",
    "    i.e.  Calibration written to \n",
    "    \n",
    "    /global/project/projectdirs/desi/spectro/sim/mjwilson/20191201/\n",
    "    \n",
    "\n",
    "    Science written to outdir. \n",
    "    '''\n",
    "    \n",
    "    logfilename  = os.path.join(os.environ['SCRATCH'] + '/svdc-summer2018/spectro/sim/bgs-gama/' + 'newexp.log')\n",
    "    #logfilename = os.path.join(simdatadir, 'newexp.log')\n",
    "    \n",
    "    if overwrite or not is_newexp_done(explist):\n",
    "        logfilename = os.path.join(simdatadir, 'newexp.log')\n",
    "        \n",
    "        print('Logging to {}'.format(logfilename))\n",
    "\n",
    "        cmd    = \" wrap-newexp --fiberassign {}\".format(fibassigndir)\n",
    "        cmd   += \" --mockdir {}\".format(targetdir)\n",
    "        cmd   += \" --obslist {}/survey/bgs-gama-exposures.fits\".format(basedir)\n",
    "        cmd   += \" --tilefile {}\".format(tilefile)\n",
    "        cmd   += \" --outdir {}/spectro/sim/bgs-gama/\".format(basedir)\n",
    "\n",
    "        if dryrun:\n",
    "          cmd += \" --dryrun\"\n",
    "        \n",
    "        if overwrite:\n",
    "            cmd += \" --force\"\n",
    "        \n",
    "        print('Starting at {}'.format(time.asctime()))\n",
    "        \n",
    "        if 'NERSC_HOST' in os.environ:\n",
    "            nodes      = 15\n",
    "            nersc_cmd  = \"srun -A desi -N {nodes} -n {nodes} -c 32\".format(nodes=nodes)\n",
    "            nersc_cmd += \" -C haswell -t 00:15:00 --qos interactive\"\n",
    "            cmd        = nersc_cmd + cmd \n",
    "            \n",
    "        if mpi: \n",
    "            cmd       += ' --mpi'\n",
    "        \n",
    "        print(cmd)\n",
    "\n",
    "        with open(logfilename, 'w') as logfile:\n",
    "            err = subprocess.call(cmd.split(), stdout=logfile, stderr=logfile)\n",
    "            \n",
    "            if err != 0:\n",
    "                print('ERROR {} running wrap-newexp; see {}'.format(err, logfilename))\n",
    "                \n",
    "            else:\n",
    "                print('done')            \n",
    "    else:\n",
    "        print('newexp is done')\n",
    "        \n",
    "        is_newexp_done(explist, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Single tile: 1 arc, 1 flat and 1 science exposure.\n",
    "%time run_newexp(os.path.join(codedir, 'bgs-gama-tiles-%s.fits' % '100000'), explist, overwrite=overwrite_simspec, mpi=True)\n",
    "\n",
    "# Single GAMA field.\n",
    "# %time run_newexp(os.path.join(codedir, 'bgs-gama-tiles_%s.fits' % 'G02'), explist, overwrite=overwrite_simspec, mpi=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate noisy uncalibrated spectra  using fastframe.\n",
    "\n",
    "fastframe is a stripped down version of quickgen, and it uses specsim under the hood. \n",
    "specsim is memory hungry so we are limited to one process per node, leaving the other \n",
    "cores idle.\n",
    "\n",
    "6.3 minutes for 12 arc, 12 flat, 18 science exposures on 15 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fastframe_done(explist, reduxdir, verbose=False):\n",
    "    nflat      = np.count_nonzero(explist['FLAVOR'] == 'flat')\n",
    "    nscience   = np.count_nonzero(explist['FLAVOR'] == 'science')\n",
    "    nframe     = 30 * (nflat + nscience)\n",
    "    \n",
    "    framefiles = glob.glob(reduxdir+'/exposures/*/*/frame*.fits')\n",
    "\n",
    "    if verbose:\n",
    "        print('{}/{} frame files'.format(len(framefiles), nframe))\n",
    "    \n",
    "    if len(framefiles) != nframe:\n",
    "        return  False\n",
    "    \n",
    "    else:\n",
    "        return  True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fastframe(overwrite=False):\n",
    "    '''\n",
    "    Debug:\n",
    "     \n",
    "    export SPECPROD='bgs-gama'\n",
    "    export  PIXPROD='bgs-gama'\n",
    "    \n",
    "    export DESI_SPECTRO_SIM=/global/cscratch1/sd/mjwilson/svdc-summer2018/spectro/sim\n",
    "    export DESI_SPECTRO_REDUX=/global/cscratch1/sd/mjwilson/svdc-summer2018/spectro/redux\n",
    "    \n",
    "    wrap-fastframe --mpi --outdir /global/cscratch1/sd/mjwilson/svdc-summer2018/spectro/fframe/bgs-gama/    \n",
    "\n",
    "\n",
    "    Example dir. structure (hand created):\n",
    "    \n",
    "    /global/cscratch1/sd/mjwilson/svdc-summer2018/spectro/sim/bgs-gama/20191201/00000002/\n",
    "\n",
    "\n",
    "    Note:  skips arcs, processes flats and science. \n",
    "            --cframe for generating calibrated spectra directly. \n",
    "\n",
    "    See: \n",
    "    \n",
    "    https://github.com/desihub/desisim/blob/master/bin/wrap-fastframe\n",
    "    https://desisim.readthedocs.io/en/latest/_modules/desisim/scripts/fastframe.html\n",
    "    \n",
    "    \n",
    "    7.4 minutes for 0 arc, 1 flat, 1 science exposures;  Success!\n",
    "    '''\n",
    "    \n",
    "    if is_fastframe_done(explist, reduxdir, verbose=True):\n",
    "        print('fastframe already done; skipping')\n",
    "        \n",
    "    else:\n",
    "        logfilename = os.path.join(reduxdir, 'exposures', 'fastframe.log')\n",
    "        \n",
    "        os.makedirs(os.path.dirname(logfilename), exist_ok=True)\n",
    "\n",
    "        print('Running fastframe batch job; should take ~7 min.')\n",
    "        print('Starting at {}'.format(time.asctime()))\n",
    "        print('Logging to {}'.format(logfilename))\n",
    "        \n",
    "        nodes   = 15\n",
    "\n",
    "        cmd     = \"srun -A desi -N {nodes} -n {nodes} -c 32 -C haswell -t 00:120:00 --qos interactive\".format(nodes=nodes)\n",
    "        cmd    += \" wrap-fastframe --mpi --clobber\"\n",
    "\n",
    "        with open(logfilename, 'w') as logfile:\n",
    "            err = subprocess.call(cmd.split(), stdout=logfile, stderr=logfile)\n",
    "            \n",
    "            if err != 0:\n",
    "                print('ERROR {} running wrap-fastframe; see {}'.format(err, logfilename))\n",
    "            \n",
    "            else:\n",
    "                print('Done at {}'.format(time.asctime()))\n",
    "\n",
    "        if is_fastframe_done(explist, reduxdir, verbose=True):\n",
    "            print('SUCCESS')\n",
    "        \n",
    "        else:\n",
    "            print('ERROR; see {}'.format(logfilename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fastframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Check individual framefile outputs\n",
    "ntot = 0\n",
    "nbad = 0\n",
    "\n",
    "for night, expid, flavor in explist['NIGHT', 'EXPID', 'FLAVOR']:\n",
    "    if flavor != 'flat' and flavor != 'science':\n",
    "        continue\n",
    "\n",
    "    for channel in ['b', 'r', 'z']:\n",
    "        for spectrograph in range(10):\n",
    "            camera    = channel + str(spectrograph)\n",
    "            framefile = desispec.io.findfile('frame', night, expid, camera)\n",
    "            ntot     += 1\n",
    "            \n",
    "            if not os.path.exists(framefile):\n",
    "                nbad += 1\n",
    "                print('Missing {} frame {}'.format(flavor, framefile))\n",
    "\n",
    "if nbad > 0:\n",
    "    print('Missing {}/{} frame files'.format(nbad, ntot))\n",
    "\n",
    "else:\n",
    "    print('All {} science and flat frame files generated'.format(ntot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the spectro pipeline\n",
    "### First, create the production database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv('DESI_SPECTRO_DATA'))\n",
    "print(os.getenv('DESI_SPECTRO_REDUX'))\n",
    "print(os.getenv('SPECPROD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desispec.io import get_pipe_database\n",
    "\n",
    "\n",
    "pipedbfile = get_pipe_database()\n",
    "\n",
    "if not os.path.exists(pipedbfile):\n",
    "    cmd = \"desi_pipe create --db-postgres --force\"\n",
    "    cmd += \" --data {}\".format(os.getenv('DESI_SPECTRO_DATA'))\n",
    "    cmd += \" --redux {}\".format(os.getenv('DESI_SPECTRO_REDUX'))\n",
    "    cmd += \" --prod {}\".format(os.getenv('SPECPROD'))\n",
    "    \n",
    "    print(cmd)\n",
    "    \n",
    "    err = subprocess.call(cmd.split())\n",
    "    \n",
    "    assert err == 0\n",
    "    \n",
    "    ##  '/global/cscratch1/sd/mjwilson/svdc-summer2018/spectro/redux/bgs-gama/desi.db'\n",
    "    assert os.path.exists(desispec.io.get_pipe_database())\n",
    "    \n",
    "    print('SUCCESS')\n",
    "    \n",
    "else:\n",
    "    print('spectro pipeline DB file (%s) already exists; skipping' % pipedbfile)\n",
    "    \n",
    "##  Set environment variable for product. \n",
    "os.environ['DESI_SPECTRO_DB'] = os.getenv('DESI_SPECTRO_REDUX') + '/' + os.getenv('SPECPROD') + '/desi.db'\n",
    "\n",
    "print('\\n\\nSet $DESI_SPECTRO_DB to:  ' + os.getenv('DESI_SPECTRO_DB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_setup_file = desispec.io.specprod_root() + '/setup.sh'\n",
    "\n",
    "with open(pipe_setup_file) as fx:\n",
    "    for line in fx:\n",
    "        line = line.strip()\n",
    "        if line.startswith('export '):\n",
    "            keyvalue = line.split(' ')[1]\n",
    "            key, value = keyvalue.split('=', maxsplit=1)\n",
    "            if key in ('DESI_SPECTRO_REDUX', 'SPECPROD'):\n",
    "                continue\n",
    "            if key in os.environ and value != os.environ[key]:\n",
    "                print('{} {} -> {}'.format(key, os.environ[key], value))\n",
    "            elif key not in os.environ:\n",
    "                print('Setting {}={}'.format(key, value))\n",
    "            \n",
    "            os.environ[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sync up with the actual files on disk\n",
    "\n",
    "We didn't start with raw data files, so we'll skip over extraction and PSF-fitting steps.\n",
    "`desi_pipe sync` will update the database from what files are actually on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = subprocess.call('desi_pipe sync'.split())\n",
    "\n",
    "assert err == 0\n",
    "\n",
    "output = subprocess.check_output('desi_pipe top --once'.split())\n",
    "\n",
    "print(output.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "Preproc has fibermap and rawdata dependencies.  Currently, nothing happens as \n",
    "the state of rawdata is ready, rather than done. \n",
    "\n",
    "Cheap hack that would fix this:                                                                             cur.execute(\"UPDATE {tn} SET {cn}=3\".format(tn='rawdata', cn='state'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline scripts as a series of interactive jobs\n",
    "\n",
    "`desi_pipe chain` would be a more convenient way of doing this,\n",
    "but for the minitest it takes too long to wait for N>>1 jobs in the debug queue.\n",
    "\n",
    "\n",
    "Ensure exposures are in:\n",
    "\n",
    "DESI_SPECTRO_REDUX/SPECPROD/exposures/night/\n",
    "\n",
    "as per get_exposures of \n",
    "\n",
    "https://github.com/desihub/desispec/blob/012070d7121a6c6c74ea51958667d49feb8bfa02/py/desispec/io/meta.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desispec.pipeline import load_db\n",
    "\n",
    "\n",
    "taskdir   = os.path.join(desispec.io.get_pipe_rundir(), 'minitest')\n",
    "\n",
    "os.makedirs(taskdir, exist_ok=True)\n",
    "\n",
    "dbpath    = desispec.io.get_pipe_database()\n",
    "db        = load_db(dbpath, mode=\"w\")\n",
    "\n",
    "tasktypes = ['fiberflat', 'fiberflatnight', 'sky', 'starfit', 'fluxcalib', 'cframe', 'spectra', 'redshift']\n",
    "\n",
    "\n",
    "print('Loading database:  %s' % dbpath)\n",
    "\n",
    "for tasktype in tasktypes:\n",
    "    for night in np.unique(explist['NIGHT']):\n",
    "        print('Getting ready for night: %s' % night)\n",
    "        \n",
    "        ##  /global/common/software/desi/cori/desiconda/20180709-1.2.6-spec/code/desispec/0.27.0/lib/python3.6/site-packages/desispec-0.27.0-py3.6.egg/desispec/pipeline/db.py\n",
    "        db.getready(night)\n",
    "\n",
    "    taskfile = \"{}/{}.tasks\".format(taskdir, tasktype)\n",
    "\n",
    "    cmd  = \"desi_pipe tasks --tasktype {} --states ready,waiting \".format(tasktype)\n",
    "    cmd += \" > {}\".format(taskfile)\n",
    "    \n",
    "    print('\\n' + cmd)\n",
    "    \n",
    "    try:\n",
    "        subprocess.check_call(cmd, shell=True)\n",
    "    \n",
    "    except subprocess.CalledProcessError:\n",
    "        print('FAILED: {}'.format(cmd))\n",
    "    \n",
    "        break\n",
    "\n",
    "    task_count = db.count_task_states(tasktype)\n",
    "\n",
    "    print()\n",
    "    print(task_count)\n",
    "\n",
    "    if tasktype == 'redshift':\n",
    "        ranks_per_task = 32\n",
    "        cores_per_rank = 2\n",
    "        n              = task_count['ready'] * ranks_per_task // 2  #- two iterations\n",
    "        nodes          = (n-1) // 32 + 1\n",
    "        runtime        = 59    #- minutes\n",
    "    \n",
    "    elif tasktype == 'spectra':\n",
    "        ranks_per_task = 1\n",
    "        cores_per_rank = 8\n",
    "        n              = task_count['ready'] * ranks_per_task\n",
    "        runtime        = 20    #- minutes\n",
    "    \n",
    "    else:\n",
    "        ranks_per_task = 1\n",
    "        cores_per_rank = 2\n",
    "        n              = task_count['ready'] * ranks_per_task\n",
    "        runtime        = 15    #- minutes\n",
    "\n",
    "    nodes = (n*cores_per_rank-1) // 64 + 1\n",
    "\n",
    "    if n > 0:\n",
    "        t0 = time.time()\n",
    "\n",
    "        cmd = 'srun -A desi -t {}:00 -C haswell --qos interactive'.format(runtime)\n",
    "        cmd += ' -N {nodes} -n {procs} -c {cores} '.format(nodes=nodes, procs=n, cores=cores_per_rank)\n",
    "        cmd += ' desi_pipe_exec_mpi --tasktype {} --taskfile {}'.format(tasktype, taskfile)\n",
    "        \n",
    "        logfilename = '{}/{}.log'.format(taskdir, tasktype)\n",
    "        \n",
    "        print('Running {} {} tasks'.format(n, tasktype))\n",
    "        print('Logging to {}'.format(logfilename))\n",
    "        print(cmd)\n",
    "        \n",
    "        with open(logfilename, 'w') as logfile:\n",
    "            err = subprocess.call(cmd.split(), stdout=logfile, stderr=logfile)\n",
    "        \n",
    "            if err != 0:\n",
    "                print('    ERROR {} for tasktype {}'.format(err, tasktype))\n",
    "                print('    See {}'.format(logfilename))\n",
    "            \n",
    "            else:\n",
    "                dt = time.time() - t0\n",
    "                print('  DONE at {}'.format(time.asctime()))\n",
    "                print('  {} took {:.1f} min'.format(tasktype, dt/60))\n",
    "    \n",
    "    elif task_count['waiting'] == 0 and task_count['done'] > 0:\n",
    "        print('All {} tasks already run'.format(tasktype))\n",
    "    \n",
    "    else:\n",
    "        print('No {} tasks ready to run; skipping'.format(tasktype))\n",
    "\n",
    "for night in np.unique(explist['NIGHT']):\n",
    "    db.getready(night)\n",
    "\n",
    "print(subprocess.check_output('desi_pipe top --once'.split()).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "DESI master",
   "language": "python",
   "name": "desi-master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
